{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Low-Rank RoBERTa: Achieving High Accuracy Under 1M Parameters**"
      ],
      "metadata": {
        "id": "tnVehb-aVvxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook implements a modified RoBERTa architecture for text classification on the AG News dataset using Low-Rank Adaptation"
      ],
      "metadata": {
        "id": "p1Zu9GOiV5H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "id": "7KgaGv6qHZNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from datasets import load_dataset, Dataset, concatenate_datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch\n",
        "import json, re, pickle, random, string\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# Import nltk for augmentation functions\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download nltk resources\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# Set device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "id": "0DjxKM1KLclF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text augmentation functions\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def get_synonyms(word):\n",
        "    \"\"\"Return a list of synonyms for a word from WordNet (excluding itself).\"\"\"\n",
        "    syns = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            name = lemma.name().replace('_', ' ')\n",
        "            if name.lower() != word.lower():\n",
        "                syns.add(name)\n",
        "    return list(syns)\n",
        "\n",
        "def synonym_replacement_rate(text, rate=0.01):\n",
        "    \"\"\"\n",
        "    Replace approximately `rate` fraction of non-stopwords in the text with synonyms.\n",
        "    \"\"\"\n",
        "    words = word_tokenize(text)\n",
        "    # indices of words eligible for replacement\n",
        "    candidates = [i for i, w in enumerate(words)\n",
        "                  if w.isalpha() and w.lower() not in stop_words]\n",
        "    # how many to replace\n",
        "    n_replace = int(len(candidates) * rate)\n",
        "    if n_replace < 1:\n",
        "        return text  # rate too low → no changes\n",
        "\n",
        "    random.shuffle(candidates)\n",
        "    replaced = 0\n",
        "    for idx in candidates:\n",
        "        syns = get_synonyms(words[idx])\n",
        "        if syns:\n",
        "            words[idx] = random.choice(syns)\n",
        "            replaced += 1\n",
        "        if replaced >= n_replace:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "def aug_html_entities(text: str, p=0.1) -> str:\n",
        "    entities = {\"'\": \"&#39;\", '\"': \"&quot;\", \"&\": \"&amp;\"}\n",
        "    for ch, ent in entities.items():\n",
        "        if random.random() < p:\n",
        "            text = text.replace(ch, ent)\n",
        "    return text\n",
        "\n",
        "def aug_word_dup(text: str, p=0.05) -> str:\n",
        "    words = text.split()\n",
        "    if words and random.random() < p:\n",
        "        i = random.randrange(len(words))\n",
        "        words.insert(i, words[i])\n",
        "    return \" \".join(words)\n",
        "\n",
        "def aug_case_swap(text: str, p=0.1) -> str:\n",
        "    return \"\".join(c.upper() if random.random() < p else c.lower() for c in text)\n",
        "\n",
        "def aug_punct_space(text: str, p=0.05) -> str:\n",
        "    # sprinkle punctuation\n",
        "    out = []\n",
        "    for c in text:\n",
        "        if c.isalnum() and random.random() < p:\n",
        "            out.append(c + random.choice(string.punctuation))\n",
        "        else:\n",
        "            out.append(c)\n",
        "    s = \"\".join(out)\n",
        "    return re.sub(r\" \", lambda m: \" \" + (\" \" if random.random() < p else \"\"), s)\n",
        "\n",
        "def aug_truncate(text: str, p=0.1) -> str:\n",
        "    if random.random() < p and len(text) > 20:\n",
        "        cut = int(len(text) * random.uniform(0.7, 0.9))\n",
        "        return text[:cut]\n",
        "    return text\n",
        "\n",
        "def aug_char_swap(text: str, p=0.02) -> str:\n",
        "    chars = list(text)\n",
        "    for i in range(len(chars) - 1):\n",
        "        if random.random() < p:\n",
        "            chars[i], chars[i+1] = chars[i+1], chars[i]\n",
        "    return \"\".join(chars)\n",
        "\n",
        "def augment_text(text: str) -> str:\n",
        "    aug_funcs = [\n",
        "        aug_html_entities,\n",
        "        aug_word_dup,\n",
        "        aug_case_swap,\n",
        "        aug_punct_space,\n",
        "        aug_truncate,\n",
        "        aug_char_swap,\n",
        "        synonym_replacement_rate\n",
        "    ]\n",
        "\n",
        "    n = random.randint(1, 5)\n",
        "    # pick n distinct functions\n",
        "    chosen = random.sample(aug_funcs, k=n)\n",
        "    # apply them in sequence\n",
        "    for fn in chosen:\n",
        "        text = fn(text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "zK6zooTCLhn4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset and labels\n",
        "agnews = load_dataset(\"ag_news\")\n",
        "class_names = agnews[\"train\"].features[\"label\"].names\n",
        "id2label = {i: name for i, name in enumerate(class_names)}\n",
        "label2id = {name: i for i, name in enumerate(class_names)}\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "\n",
        "# define company list for masking\n",
        "COMPANY_LIST = [\n",
        "    \"google\", \"apple\", \"microsoft\", \"amazon\", \"facebook\", \"tesla\",\n",
        "    \"oracle\", \"ibm\", \"intel\", \"nvidia\", \"qualcomm\", \"sap\",\n",
        "    \"salesforce\", \"uber\", \"airbnb\", \"twitter\", \"meta\", \"snap\",\n",
        "    \"zoom\", \"palantir\"\n",
        "]\n",
        "\n",
        "# text preprocessing functions\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def mask_text(text: str) -> str:\n",
        "    t = text.replace(\"\\n\", \" \").strip().lower()\n",
        "    t = ''.join('[NUM]' if ch.isdigit() else ch for ch in t)\n",
        "    for comp in COMPANY_LIST:\n",
        "        t = re.sub(rf\"\\b{comp}\\b\", '[COMPANY]', t)\n",
        "    return t\n",
        "\n",
        "\n",
        "print(\"creating a new augmented dataset...\")\n",
        "random.seed(42)\n",
        "orig = load_dataset(\"ag_news\", split=\"train\")  # 120K examples\n",
        "\n",
        "# Create a balanced subset for augmentation\n",
        "labels = sorted(set(orig[\"label\"]))\n",
        "n_per = 40_000 // len(labels)\n",
        "indices_by_label = {lab: [] for lab in labels}\n",
        "for i, lab in enumerate(orig[\"label\"]):\n",
        "    indices_by_label[lab].append(i)\n",
        "\n",
        "sampled_idxs = []\n",
        "for lab in labels:\n",
        "    sampled_idxs += random.sample(indices_by_label[lab], n_per)\n",
        "subset_30k = orig.select(sampled_idxs)\n",
        "\n",
        "# Select 80000 from orig\n",
        "new_orig = orig.shuffle(seed=42).select(range(80_000))\n",
        "\n",
        "def perturb(ex):\n",
        "    return {\"text\": augment_text(ex[\"text\"])}\n",
        "\n",
        "perturbed_30k = subset_30k.map(perturb)\n",
        "train_dataset = concatenate_datasets([new_orig, perturbed_30k])\n",
        "print(f\"Created augmented dataset with {len(train_dataset)} examples\")\n",
        "\n",
        "# Load test dataset\n",
        "test_dataset = load_dataset(\"ag_news\", split=\"test\")\n",
        "print(f\"Test dataset has {len(test_dataset)} examples\")\n"
      ],
      "metadata": {
        "id": "A8jMswisLjJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "model_id = \"roberta-base\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    examples[\"text\"] = [preprocess(text) for text in examples[\"text\"]]\n",
        "    examples[\"text\"] = [mask_text(text) for text in examples[\"text\"]]\n",
        "    examples[\"text\"] = [text.replace(\"\\n\", \" \") for text in examples[\"text\"]]\n",
        "\n",
        "    tokenizer_resp = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    examples[\"input_ids\"] = tokenizer_resp[\"input_ids\"]\n",
        "    examples[\"attention_mask\"] = tokenizer_resp[\"attention_mask\"]\n",
        "    return examples\n",
        "\n",
        "# Process datasets\n",
        "train_dataset = train_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"],\n",
        ")\n",
        "\n",
        "test_dataset = test_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"],\n",
        ")\n",
        "\n",
        "print(\"Dataset preparation complete\")\n"
      ],
      "metadata": {
        "id": "dBm5Xj2kLqtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=4,\n",
        "    id2label=id2label,\n",
        ").to(device)\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=2,\n",
        "    lora_alpha=4,\n",
        "    target_modules=[\"value\", \"query\", \"key\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias='none',\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        ")\n",
        "\n",
        "# Apply LoRA to model\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "print(lora_model.print_trainable_parameters())\n",
        "\n",
        "# Define data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "# Training parameters\n",
        "train_batch_size = 64\n",
        "test_batch_size = 32\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=train_batch_size,\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=test_batch_size,\n",
        ")\n",
        "\n",
        "print(f\"Training on {len(train_dataset)} examples with batch size {train_batch_size}\")\n",
        "print(f\"Testing on {len(test_dataset)} examples with batch size {test_batch_size}\")\n"
      ],
      "metadata": {
        "id": "T6NBLWBzL1qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define metrics computation function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy\n",
        "    }\n",
        "\n",
        "# Define training arguments\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=train_batch_size,\n",
        "    per_device_eval_batch_size=test_batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    optim=\"adamw_torch\",\n",
        "    label_names=[\"label\"],\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=trainer_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "-B2WovmNL-Cb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "\n",
        "# Add tracking lists for manual plotting (from first code)\n",
        "train_losses, train_accuracies = [], []\n",
        "test_losses, test_accuracies = [], []\n",
        "\n",
        "# Training loop with manual tracking\n",
        "for epoch in range(int(trainer_args.num_train_epochs)):\n",
        "    # Train for one epoch\n",
        "    trainer.train(resume_from_checkpoint=False if epoch==0 else True)\n",
        "\n",
        "    # Evaluate and collect metrics\n",
        "    train_metrics = trainer.evaluate(eval_dataset=train_dataset)\n",
        "    eval_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "    train_losses.append(train_metrics['eval_loss'])\n",
        "    train_accuracies.append(train_metrics['eval_accuracy'])\n",
        "    test_losses.append(eval_metrics['eval_loss'])\n",
        "    test_accuracies.append(eval_metrics['eval_accuracy'])\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{trainer_args.num_train_epochs} — \"\n",
        "          f\"Train Loss: {train_metrics['eval_loss']:.4f}, \"\n",
        "          f\"Train Acc: {train_metrics['eval_accuracy']:.4f} — \"\n",
        "          f\"Test Loss: {eval_metrics['eval_loss']:.4f}, \"\n",
        "          f\"Test Acc: {eval_metrics['eval_accuracy']:.4f}\")\n",
        "\n",
        "    # Plot after each epoch (from first code)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(0, epoch+1), train_losses, label=\"Train Loss\")\n",
        "    plt.plot(range(0, epoch+1), test_losses, label=\"Test Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Loss - Epoch {epoch+1}\")\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(0, epoch+1), train_accuracies, label=\"Train Acc\")\n",
        "    plt.plot(range(0, epoch+1), test_accuracies, label=\"Test Acc\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Accuracy - Epoch {epoch+1}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Save the model\n",
        "output_dir = \"final_model\"\n",
        "trainer.save_model(output_dir)\n",
        "print(f\"Model saved to {output_dir}\")\n"
      ],
      "metadata": {
        "id": "0WXitmvEMEfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get final accuracy\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "accuracy = accuracy_score(test_dataset[\"label\"], preds)\n",
        "print(f\"Final Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "I1EHK8sqMeRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Run inference on unlabeled test data if available\n",
        "try:\n",
        "    # Load unlabeled test data if exists\n",
        "    with open(\"test_unlabelled.pkl\", \"rb\") as f:\n",
        "        test_unlabelled = pickle.load(f)\n",
        "\n",
        "    # Process the unlabeled data\n",
        "    test_unlabelled = test_unlabelled.map(\n",
        "        tokenize_function,\n",
        "        batched=True,\n",
        "        remove_columns=[\"text\"],\n",
        "    )\n",
        "\n",
        "    # Make predictions\n",
        "    print(\"Making predictions on unlabeled test data...\")\n",
        "    predictions = trainer.predict(test_unlabelled)\n",
        "\n",
        "    # Format predictions\n",
        "    out = {\n",
        "        \"ID\": list(range(len(predictions.predictions))),\n",
        "        \"Label\": predictions.predictions.argmax(-1)\n",
        "    }\n",
        "\n",
        "    # Save predictions\n",
        "    output_file = \"predictions.csv\"\n",
        "    df = pd.DataFrame(out)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Predictions saved to {output_file}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"No unlabeled test data found, skipping inference\")\n"
      ],
      "metadata": {
        "id": "hBblVxksNNv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRjyWAiqMpkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r-dQgMSyMV0Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}